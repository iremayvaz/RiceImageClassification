{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-12T21:21:11.402224Z",
     "start_time": "2025-01-12T21:21:11.400307Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 145
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T21:21:11.417070Z",
     "start_time": "2025-01-12T21:21:11.415502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "id": "c58bdc5119a9df34",
   "outputs": [],
   "execution_count": 146
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T21:21:11.434055Z",
     "start_time": "2025-01-12T21:21:11.432509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_path = \"./data\"\n",
    "train_data_path = \"./DataSet/train\"\n",
    "test_data_path = \"./DataSet/test\""
   ],
   "id": "f9c07a45a9292999",
   "outputs": [],
   "execution_count": 147
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T21:21:11.436263Z",
     "start_time": "2025-01-12T21:21:11.434842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "num_classes = 6"
   ],
   "id": "7a06d6ff37ac7937",
   "outputs": [],
   "execution_count": 148
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T21:21:11.440440Z",
     "start_time": "2025-01-12T21:21:11.436709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = datasets.ImageFolder(root=train_data_path, transform=transforms.Compose([ transforms.Resize((256, 256)),  # Görüntüleri 256x256 boyutuna yeniden boyutlandır\n",
    "                                                                                    transforms.CenterCrop(224),\n",
    "                                                                                    transforms.ToTensor()])         )\n",
    "loader = DataLoader(train_data_path, batch_size=1, shuffle=False)"
   ],
   "id": "47d3d77520ab36f3",
   "outputs": [],
   "execution_count": 149
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T21:21:11.443190Z",
     "start_time": "2025-01-12T21:21:11.441310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate mean and standard deviation for normalization\n",
    "'''mean = 0.0\n",
    "std = 0.0\n",
    "for img, _ in loader:\n",
    "    mean = mean + img.mean(dim=[0, 2, 3])\n",
    "    std = std + img.std(dim=[0, 2, 3])\n",
    "    \n",
    "mean = mean / len(loader.dataset)\n",
    "std = std / len(loader.dataset)\n",
    "print(f\"Mean: {mean}, Standard Deviation: {std}\")'''"
   ],
   "id": "4b1daab1a5b87dab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mean = 0.0\\nstd = 0.0\\nfor img, _ in loader:\\n    mean = mean + img.mean(dim=[0, 2, 3])\\n    std = std + img.std(dim=[0, 2, 3])\\n    \\nmean = mean / len(loader.dataset)\\nstd = std / len(loader.dataset)\\nprint(f\"Mean: {mean}, Standard Deviation: {std}\")'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 150
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T21:21:11.445278Z",
     "start_time": "2025-01-12T21:21:11.443684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# DATA PREPROCESSING\n",
    "transform = transforms.Compose([ transforms.Resize((256, 256)), \n",
    "                                 transforms.CenterCrop(224),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize(mean=(0.5, 0.5, 0.5) , std=(0.5, 0.5, 0.5)) ]) "
   ],
   "id": "5367d873e196d501",
   "outputs": [],
   "execution_count": 151
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T21:21:11.448530Z",
     "start_time": "2025-01-12T21:21:11.446288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataset ve DataLoader\n",
    "'''dataset = datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "loader = DataLoader(train_data_path, batch_size=1, shuffle=True)  # 1 görüntü ile kontrol\n",
    "\n",
    "# Normalize edilmiş görüntüyü kontrol et\n",
    "for img, _ in loader:\n",
    "    print(\"Mean:\", img.mean(dim=[0, 2, 3]))  # Kanal başına ortalama\n",
    "    print(\"Standard Deviation:\", img.std(dim=[0, 2, 3]))  # Kanal başına std\n",
    "    break  # İlk görüntü ile kontrol yeterlidir'''"
   ],
   "id": "c3137675fb844da4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataset = datasets.ImageFolder(root=train_data_path, transform=transform)\\nloader = DataLoader(train_data_path, batch_size=1, shuffle=True)  # 1 görüntü ile kontrol\\n\\n# Normalize edilmiş görüntüyü kontrol et\\nfor img, _ in loader:\\n    print(\"Mean:\", img.mean(dim=[0, 2, 3]))  # Kanal başına ortalama\\n    print(\"Standard Deviation:\", img.std(dim=[0, 2, 3]))  # Kanal başına std\\n    break  # İlk görüntü ile kontrol yeterlidir'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 152
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T21:21:11.451688Z",
     "start_time": "2025-01-12T21:21:11.449217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SPLIT DATA\n",
    "# Eğitim ve test verilerini yükleme\n",
    "train_dataset = datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_data_path, transform=transform)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ],
   "id": "6eca537e070e8ab3",
   "outputs": [],
   "execution_count": 153
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T21:21:11.454622Z",
     "start_time": "2025-01-12T21:21:11.452686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# DEFINE the CNN Architecture\n",
    "class CNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNet, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(16, 32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) )\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 4 * 4, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ],
   "id": "5e3b617e2e70b7c0",
   "outputs": [],
   "execution_count": 154
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T21:21:11.457860Z",
     "start_time": "2025-01-12T21:21:11.455209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the model\n",
    "model = CNNet().to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "id": "a56f391292abd8e",
   "outputs": [],
   "execution_count": 155
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T21:21:11.635887Z",
     "start_time": "2025-01-12T21:21:11.470976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training loop\n",
    "start = time.time()\n",
    "\n",
    "total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device) # 64 x 3 x 32 x 32\n",
    "        labels = labels.to(device) # 64 x 10\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images) # 64 x 10\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_steps}], Loss: {loss.item():.4f}')\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Training finished in {end - start} sec!\")"
   ],
   "id": "b3b4a50a56f2875a",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x93312 and 512x512)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[156], line 11\u001B[0m\n\u001B[1;32m      8\u001B[0m labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mto(device) \u001B[38;5;66;03m# 64 x 10\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# Forward pass\u001B[39;00m\n\u001B[0;32m---> 11\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# 64 x 10\u001B[39;00m\n\u001B[1;32m     12\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, labels)\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# Backward and optimize\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "Cell \u001B[0;32mIn[154], line 24\u001B[0m, in \u001B[0;36mCNNet.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m     23\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv_layers(x)\n\u001B[0;32m---> 24\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfc_layers\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     25\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/container.py:250\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    248\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    249\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 250\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    251\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/linear.py:125\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (32x93312 and 512x512)"
     ]
    }
   ],
   "execution_count": 156
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "AĞAÇ TEMELLİ YÖNTEM",
   "id": "df97bd6dc0872297"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T21:25:27.962694Z",
     "start_time": "2025-01-12T21:25:27.843069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LOAD DATA\n",
    "\n",
    "# Görseller ve etiketler için boş listeler\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Sınıf isimlerini al (örneğin, 'Arborio', 'Basmati' gibi)\n",
    "classes = os.listdir(data_path)\n",
    "class_indices = {cls_name: i for i, cls_name in enumerate(classes)}  # Etiketleme için\n",
    "\n",
    "# Görselleri ve etiketleri yükle\n",
    "for cls_name in classes:\n",
    "    cls_path = os.path.join(data_path, cls_name)\n",
    "    for img_name in os.listdir(cls_path):\n",
    "        img_path = os.path.join(cls_path, img_name)\n",
    "\n",
    "        # Görselleri yükle ve boyutunu kontrol et\n",
    "        image = Image.open(img_path).convert(\"L\")  # Gri tonlamalı\n",
    "        image = image.resize((256, 256))  # Eğer boyut farklıysa yeniden boyutlandır\n",
    "\n",
    "        # Görselleri ve etiketleri listeye ekle\n",
    "        images.append(np.array(image))  # Görselleri numpy dizisine dönüştür\n",
    "        labels.append(class_indices[cls_name])  # Etiketi ekle\n"
   ],
   "id": "e4456e654ea05820",
   "outputs": [],
   "execution_count": 174
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T21:25:31.439043Z",
     "start_time": "2025-01-12T21:25:31.434239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Görseller ve etiketleri NumPy dizilerine dönüştür\n",
    "images = np.array(images)  # Görseller (n, 250, 250)\n",
    "labels = np.array(labels)  # Etiketler (n, )\n",
    "\n",
    "print(f\"Toplam Görsel: {len(images)}\")\n",
    "print(f\"Görsellerin Boyutu: {images.shape}\")\n",
    "print(f\"Etiketlerin Boyutu: {labels.shape}\")\n"
   ],
   "id": "be736266eca0dc0d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam Görsel: 186\n",
      "Görsellerin Boyutu: (186, 256, 256)\n",
      "Etiketlerin Boyutu: (186,)\n"
     ]
    }
   ],
   "execution_count": 175
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T21:25:32.691309Z",
     "start_time": "2025-01-12T21:25:32.674362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SCALE DATA\n",
    "images = images / 255.0"
   ],
   "id": "f460be7c283b32b4",
   "outputs": [],
   "execution_count": 176
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T21:25:35.505106Z",
     "start_time": "2025-01-12T21:25:35.501427Z"
    }
   },
   "cell_type": "code",
   "source": "images[0].max()",
   "id": "a700629f2ecf00de",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 177
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T21:25:42.866160Z",
     "start_time": "2025-01-12T21:25:42.770694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Öznitelik çıkarma: Histogram\n",
    "def extract_features(image):\n",
    "    return np.histogram(image.ravel(), bins=256, range=(0, 256))[0]\n",
    "\n",
    "# Tüm görüntüler için öznitelik çıkarımı\n",
    "features = np.array([extract_features(image) for image in images]) "
   ],
   "id": "d2a1225f1e86462f",
   "outputs": [],
   "execution_count": 178
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T21:52:59.955062Z",
     "start_time": "2025-01-12T21:52:59.950978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SPLIT DATA\n",
    "\n",
    "# Veriyi eğitim ve test olarak ayırma\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42) # öznitelik ve etiketlere göre\n",
    "\n",
    "print(f\"Eğitim Verisi: {X_train.shape}, Test Verisi: {X_test.shape}\")"
   ],
   "id": "aaa73f789e4cec26",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eğitim Verisi: (148, 256), Test Verisi: (38, 256)\n"
     ]
    }
   ],
   "execution_count": 191
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T21:53:00.940251Z",
     "start_time": "2025-01-12T21:53:00.893681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Random Forest modelini oluşturma ve eğitme\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "start = time.time()\n",
    "rf_model.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Training in Random Forest finished in {end - start} sec!\")"
   ],
   "id": "bac728b9b2d85bc6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training in Random Forest finished in 0.044523000717163086 sec!\n"
     ]
    }
   ],
   "execution_count": 192
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T21:53:02.249006Z",
     "start_time": "2025-01-12T21:53:02.237632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test verisi üzerinde tahmin\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Doğruluk hesaplama\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Karışıklık matrisi\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Detaylı sınıflandırma raporu\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ],
   "id": "67c9c6fe2bb559cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.50\n",
      "Confusion Matrix:\n",
      "[[4 1 2 0 1 0]\n",
      " [0 2 0 0 1 0]\n",
      " [0 2 0 3 0 0]\n",
      " [0 0 0 8 0 0]\n",
      " [0 1 0 0 5 0]\n",
      " [1 0 1 6 0 0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.50      0.62         8\n",
      "           1       0.33      0.67      0.44         3\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.47      1.00      0.64         8\n",
      "           4       0.71      0.83      0.77         6\n",
      "           5       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.50        38\n",
      "   macro avg       0.39      0.50      0.41        38\n",
      "weighted avg       0.41      0.50      0.42        38\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 193
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
